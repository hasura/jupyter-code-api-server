{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate synthetic data for a single server\n",
    "def generate_server_data(server_id, num_servers, num_hours=24):\n",
    "    timestamps = pd.date_range(start='2023-08-01', periods=num_hours*60, freq='T')\n",
    "    request_counts = np.random.normal(100, 50, num_hours*60).astype(int)\n",
    "    request_counts = np.maximum(request_counts, 1)  # Ensure all counts are at least 1\n",
    "\n",
    "    # Normal distribution of CPU usage between 40% and 80%\n",
    "    # Cap lower CPU usage at 10% and upper CPU usage at 80%\n",
    "    cpu_usage = np.random.normal(50, 25, num_hours*60)\n",
    "    cpu_usage = np.maximum(cpu_usage, 0) # Ensure all CPU usage are at least 0\n",
    "    cpu_usage = np.minimum(cpu_usage, 100) # Ensure all CPU usage are at most 100\n",
    "\n",
    "    memory_usage = np.random.normal(50, 25, num_hours*60)  # Random memory usage between 40% and 90%\n",
    "    memory_usage = np.maximum(memory_usage, 0) # Ensure all memory usage are at least 0\n",
    "    memory_usage = np.minimum(memory_usage, 100) # Ensure all memory usage are at most 100\n",
    "\n",
    "    execution_time = np.random.normal(10, 25, num_hours*60)  # Random execution time between 10ms and 50ms\n",
    "    execution_time = np.maximum(execution_time, 1) # Ensure all execution time are at least 1ms\n",
    "    execution_time = np.minimum(execution_time, 50) # Ensure all execution time are at most 50ms\n",
    "\n",
    "    request_id_offset = (np.arange(num_hours*60) // num_servers) * num_servers\n",
    "    request_id = np.arange(1, len(timestamps) + 1) + request_id_offset\n",
    "\n",
    "    # Generate a numpy list of project ids between 1 to 3\n",
    "    project_id = np.random.randint(1, 4, num_hours*60) \n",
    "\n",
    "    # # Generate gdpr_list, if project_id is 1 then gdpr is True else False\n",
    "    # gdpr_list = np.where(project_id == 2, True, False)\n",
    "\n",
    "    data = {\n",
    "        'timestamp': timestamps,\n",
    "        'request_id': request_id,\n",
    "        'server_id': [f'Server_{server_id}'] * len(timestamps),\n",
    "        'project_id' : [f'Project_{i}' for i in project_id],\n",
    "        'number_of_active_requests': request_counts,\n",
    "        'cpu_usage': cpu_usage,\n",
    "        'memory_usage': memory_usage,\n",
    "        'execution_time': execution_time,\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate synthetic data for all servers in a round-robin manner\n",
    "def generate_data_for_all_servers(num_servers=10, num_hours=24):\n",
    "    all_server_data = []\n",
    "    for server_id in range(1, num_servers+1):\n",
    "        server_data = generate_server_data(server_id, num_servers, num_hours)\n",
    "        all_server_data.append(server_data)\n",
    "\n",
    "    # Concatenate data for all servers and sort by timestamp\n",
    "    all_data = pd.concat(all_server_data)\n",
    "    all_data = all_data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "    all_data['request_id'] = range(1, len(all_data) + 1)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Function to identify incidents based on latency greater than 20ms\n",
    "def identify_incidents(data):\n",
    "    data['incident'] = data['execution_time'].apply(lambda x: x > 20)\n",
    "    incident_data = data[data['incident'] == True].copy(deep=True)\n",
    "    incident_data['incident_id'] = range(1, len(incident_data) + 1)\n",
    "    incident_data = incident_data[['incident_id', 'timestamp', 'request_id']]\n",
    "    return incident_data\n",
    "\n",
    "# Function to generate aggregated server metrics\n",
    "def generate_aggregated_metrics(data):\n",
    "    aggregated_data = data.groupby(['server_id', pd.Grouper(key='timestamp', freq='H')]).agg(\n",
    "        avg_cpu_usage=('cpu_usage', 'mean'),\n",
    "        avg_memory_usage=('memory_usage', 'mean'),\n",
    "        total_requests=('number_of_active_requests', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    aggregated_data['timestamp'] = aggregated_data['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return aggregated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for all servers in a round-robin manner\n",
    "all_data = generate_data_for_all_servers(num_servers=10, num_hours=24)\n",
    "\n",
    "# Identify incidents and add incident_id column\n",
    "incident_data = identify_incidents(all_data)\n",
    "\n",
    "# Generate aggregated server metrics\n",
    "aggregated_data = generate_aggregated_metrics(all_data)\n",
    "\n",
    "# Save dataframes to CSV files\n",
    "data_folder = 'data'\n",
    "\n",
    "# Generate data_folder if doesn't exists\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "all_data[['request_id', 'timestamp', 'project_id', 'server_id',\n",
    "            'number_of_active_requests', 'cpu_usage', 'memory_usage',\n",
    "            'execution_time']].to_csv(f'{data_folder}/request.csv', index=False)\n",
    "incident_data.to_csv(f'{data_folder}/incident.csv', index=False)\n",
    "aggregated_data.to_csv(f'{data_folder}/aggregated_server_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
