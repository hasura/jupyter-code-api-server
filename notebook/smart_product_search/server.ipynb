{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b58a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET /hello_world\n",
    "\n",
    "import json\n",
    "print(json.dumps({\n",
    "  'hello': 'world'\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c66d6",
   "metadata": {},
   "source": [
    "## Template for event trigger to ETL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d18f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST /handle_event\n",
    "\n",
    "GRAPHQL_ENDPOINT = \"\"\n",
    "ADMIN_SECRET = \"\"\n",
    "\n",
    "import json\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "def handle_insert(row, client):\n",
    "    print(\"handle_insert got called\")\n",
    "    id = int(row['id'])\n",
    "    name = str(row['name'])\n",
    "    description = str(row['description'])\n",
    "    # In reality you would follow the URL from row['url']\n",
    "    content = description\n",
    "    gql_query = gql(\"\"\"\n",
    "            mutation insertItem($id: int!, $name: text!, $description: text!) {\n",
    "                insert_Product_vectors_one(object: { product_id: $id, name: $name, description: $description }) {\n",
    "                    id\n",
    "                }\n",
    "            }\n",
    "        \"\"\")\n",
    "    print(client.execute(gql_query, variable_values={\n",
    "        'id': id, 'name': name, 'description': description}))\n",
    "\n",
    "\n",
    "def handle_event(request):\n",
    "    print(\"handle_event function got called\")\n",
    "    gql_headers = {'x-hasura-admin-secret': ADMIN_SECRET}\n",
    "    # Create a GraphQL client with the request transport\n",
    "    transport = RequestsHTTPTransport(\n",
    "        url=GRAPHQL_ENDPOINT, headers=gql_headers)\n",
    "    client = Client(transport=transport)\n",
    "\n",
    "    event = request['body']['event']\n",
    "    op = event['op']\n",
    "    if op == 'INSERT':\n",
    "        row = event['data']['new']\n",
    "        handle_insert(row, client)\n",
    "    else:\n",
    "        print(str(event))\n",
    "    return request\n",
    "\n",
    "print(json.dumps(handle_event(json.loads(REQUEST))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResponseInfo POST /handle_event\n",
    "print(json.dumps({\n",
    "    \"headers\" : {\n",
    "        \"Content-Type\" : \"application/json\"\n",
    "    },\n",
    "    \"status\" : 200\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74f5ce",
   "metadata": {},
   "source": [
    "## Template to handle user's question by querying Weaviate + OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645780dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST /handle_query\n",
    "\n",
    "GRAPHQL_ENDPOINT = \"\"\n",
    "ADMIN_SECRET = \"\"\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "import json\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def handle_query(request):\n",
    "    user_query = request['body']['input']['user_query']\n",
    "\n",
    "    gql_headers = dict()\n",
    "    gql_headers['x-hasura-admin-secret'] = ADMIN_SECRET\n",
    "\n",
    "    # Create a GraphQL client with the request transport\n",
    "    transport = RequestsHTTPTransport(\n",
    "        url=GRAPHQL_ENDPOINT, headers=gql_headers)\n",
    "    client = Client(transport=transport)\n",
    "\n",
    "    # Send the GraphQL request\n",
    "    gql_query = gql(\"\"\"\n",
    "            query getProducts($user_query: text!) {\n",
    "                Product_vectors(where: { vector: { near_text: $user_query}}, limit: 10) {\n",
    "                    name\n",
    "                    description\n",
    "                }\n",
    "            }\n",
    "        \"\"\")\n",
    "    result = client.execute(gql_query, variable_values={\n",
    "                            'user_query': user_query})\n",
    "    prompt = \"\"\"\n",
    "    Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    \\n\n",
    "    \"\"\"\n",
    "    prompt += user_query\n",
    "\n",
    "    resumes = result[\"Product_vectors\"]\n",
    "\n",
    "    for resume in resumes:\n",
    "        prompt += \"Product Name:\"\n",
    "        prompt += resume[\"name\"]\n",
    "        prompt += \"Product Description: \"\n",
    "        prompt += resume[\"description\"]\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion: {question}\"\n",
    "\n",
    "\n",
    "    llm = OpenAI(model=\"text-davinci-003\",\n",
    "                openai_api_key=OPENAI_API_KEY)\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "\n",
    "    return chain.run({\"question\":user_query})\n",
    "\n",
    "print(json.dumps(handle_query(json.loads(REQUEST))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eab5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResponseInfo POST /handle_query\n",
    "print(json.dumps({\n",
    "    \"headers\" : {\n",
    "        \"Content-Type\" : \"application/json\"\n",
    "    },\n",
    "    \"status\" : 200\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
